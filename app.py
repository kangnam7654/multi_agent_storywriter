import gradio as gr
from langchain_ollama import ChatOllama

from src.graph import create_graph
from src.schemas.state import GraphState
from src.utils.prompt_loader import load_system_prompts


def generate_story(
    user_input: str,
    model_name: str,
    max_retries: int,
    progress=gr.Progress(),
):
    """ìŠ¤í† ë¦¬ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)"""

    if not user_input.strip():
        yield "ìŠ¤í† ë¦¬ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        return

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ (ìºì‹±ë¨)
    prompts = load_system_prompts()

    # LLM ì„¤ì •
    llm = ChatOllama(model=model_name)

    # ê·¸ë˜í”„ ìƒì„±
    graph = create_graph(
        llm=llm,
        story_writer_system_prompt=prompts.story_writer,
        director_system_prompt=prompts.director,
    )
    app = graph.compile()

    # ì´ˆê¸° ìƒíƒœ
    initial_state = GraphState(user_input=user_input, max_retries=max_retries)

    # ì¶œë ¥ ë²„í¼
    output_parts = []

    # ìŠ¤íŠ¸ë¦¬ë° ì‹¤í–‰
    for event in app.stream(initial_state, stream_mode="updates"):
        for node_name, node_output in event.items():

            if node_name == "init":
                # ìš”ì²­ íŒŒì‹± ê²°ê³¼
                if "request" in node_output and node_output["request"]:
                    req = node_output["request"]
                    output_parts.append("## ğŸ“ ìš”ì²­ ë¶„ì„\n")
                    output_parts.append(f"- **í”„ë¡¬í”„íŠ¸**: {req.summarized_prompt}\n")
                    output_parts.append(f"- **ì¥ë¥´**: {req.genre}\n")
                    output_parts.append(f"- **ìŠ¤íƒ€ì¼**: {req.style}\n")
                    output_parts.append(f"- **ë¶„ëŸ‰**: {req.length}\n\n")
                    output_parts.append("---\n\n")
                    yield "".join(output_parts)

            elif node_name == "write":
                # ìŠ¤í† ë¦¬ ì‘ì„± ê²°ê³¼
                if "story_output" in node_output and node_output["story_output"]:
                    story_out = node_output["story_output"]
                    retry_count = node_output.get("retry_count", 0)

                    if retry_count > 0:
                        output_parts.append(
                            f"## âœï¸ ìŠ¤í† ë¦¬ ìˆ˜ì • (ì‹œë„ {retry_count + 1})\n\n"
                        )
                    else:
                        output_parts.append("## âœï¸ ìŠ¤í† ë¦¬ ì´ˆì•ˆ\n\n")

                    if hasattr(story_out, "title") and story_out.title:
                        output_parts.append(f"### {story_out.title}\n\n")

                    if hasattr(story_out, "story") and story_out.story:
                        output_parts.append(f"{story_out.story}\n\n")

                    if hasattr(story_out, "notes") and story_out.notes:
                        output_parts.append(f"*ğŸ“Œ ì°¸ê³ : {story_out.notes}*\n\n")

                    output_parts.append("---\n\n")
                    yield "".join(output_parts)

            elif node_name == "review":
                # ê²€ìˆ˜ ê²°ê³¼
                if "eval_report" in node_output and node_output["eval_report"]:
                    report = node_output["eval_report"]

                    if report.is_approved:
                        output_parts.append("## âœ… ê²€ìˆ˜ í†µê³¼\n\n")
                        output_parts.append(f"**ì ìˆ˜**: {report.score}/10\n\n")
                        output_parts.append(f"**í”¼ë“œë°±**: {report.feedback}\n\n")
                    else:
                        output_parts.append("## ğŸ”„ ê²€ìˆ˜ í”¼ë“œë°±\n\n")
                        output_parts.append(f"**ì ìˆ˜**: {report.score}/10\n\n")
                        output_parts.append(f"**í”¼ë“œë°±**: {report.feedback}\n\n")
                        if report.issues:
                            output_parts.append("**ê°œì„  í•„ìš” ì‚¬í•­**:\n")
                            for issue in report.issues:
                                output_parts.append(f"- {issue}\n")
                            output_parts.append("\n")

                    output_parts.append("---\n\n")
                    yield "".join(output_parts)

                # ì™„ë£Œ ì—¬ë¶€ í™•ì¸
                if node_output.get("is_complete"):
                    output_parts.append("## ğŸ‰ ìŠ¤í† ë¦¬ ìƒì„± ì™„ë£Œ!\n")
                    yield "".join(output_parts)


def create_demo():
    """Gradio ë°ëª¨ ìƒì„±"""

    with gr.Blocks(
        title="Multi-Agent Story Writer",
        theme=gr.themes.Soft(),
    ) as demo:
        gr.Markdown(
            """
            # ğŸ“– Multi-Agent Story Writer
            
            LangGraph ê¸°ë°˜ ë©€í‹° ì—ì´ì „íŠ¸ ìŠ¤í† ë¦¬ ìƒì„±ê¸°ì…ë‹ˆë‹¤.  
            Lorebook(ì„¸ê³„ê´€ ì„¤ì •ì§‘)ì„ ì°¸ê³ í•˜ì—¬ ìŠ¤í† ë¦¬ë¥¼ ì‘ì„±í•˜ê³ , ìë™ìœ¼ë¡œ ê²€ìˆ˜í•©ë‹ˆë‹¤.
            """
        )

        with gr.Row():
            with gr.Column(scale=1):
                # ì…ë ¥ ì˜ì—­
                user_input = gr.Textbox(
                    label="ìŠ¤í† ë¦¬ ì•„ì´ë””ì–´",
                    placeholder="ì˜ˆ: ìŠ¤ì¹´ì´ë¦¼ ì§€ë°©ì„ ë°°ê²½ìœ¼ë¡œ í•œ íŒíƒ€ì§€ ëª¨í—˜ ì´ì•¼ê¸°ë¥¼ ì‘ì„±í•´ì¤˜.",
                    lines=3,
                )

                with gr.Accordion("âš™ï¸ ì„¤ì •", open=False):
                    model_name = gr.Textbox(
                        label="Ollama ëª¨ë¸",
                        value="gpt-oss:20b",
                        info="ì‚¬ìš©í•  Ollama ëª¨ë¸ ì´ë¦„",
                    )
                    max_retries = gr.Slider(
                        label="ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜",
                        minimum=1,
                        maximum=5,
                        value=3,
                        step=1,
                        info="Director í”¼ë“œë°± ë°˜ì˜ ìµœëŒ€ íšŸìˆ˜",
                    )

                generate_btn = gr.Button("âœ¨ ìŠ¤í† ë¦¬ ìƒì„±", variant="primary")

            with gr.Column(scale=2):
                # ì¶œë ¥ ì˜ì—­
                output = gr.Markdown(
                    label="ìƒì„± ê²°ê³¼",
                    value="ìŠ¤í† ë¦¬ ì•„ì´ë””ì–´ë¥¼ ì…ë ¥í•˜ê³  ìƒì„± ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.",
                )

        # ì˜ˆì‹œ
        gr.Examples(
            examples=[
                ["ìŠ¤ì¹´ì´ë¦¼ ì§€ë°©ì„ ë°°ê²½ìœ¼ë¡œ í•œ ë“œë˜ê³¤ë³¸ì˜ ëª¨í—˜ ì´ì•¼ê¸°"],
                ["í™”ì´íŠ¸ëŸ°ì—ì„œ ë²Œì–´ì§€ëŠ” ë„ë‘‘ê³¼ ê²½ë¹„ë³‘ì˜ ì¶”ê²©ì „"],
                ["ìœˆë“œí—¬ë¦„ì˜ ì–´ë‘ ì˜ í˜•ì œë‹¨ ì•”ì‚´ì ì´ì•¼ê¸°ë¥¼ ì§§ê²Œ ì¨ì¤˜"],
            ],
            inputs=user_input,
        )

        # ì´ë²¤íŠ¸ ì—°ê²°
        generate_btn.click(
            fn=generate_story,
            inputs=[user_input, model_name, max_retries],
            outputs=output,
        )

        user_input.submit(
            fn=generate_story,
            inputs=[user_input, model_name, max_retries],
            outputs=output,
        )

    return demo


if __name__ == "__main__":
    demo = create_demo()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
    )
